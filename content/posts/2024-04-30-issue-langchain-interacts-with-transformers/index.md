---
title           : "LangChain å’Œ Transformers æ­é…ä½¿ç”¨å‡ºç°çš„ç»­å†™è¡Œä¸º"
date            : 2024-04-30
isCJKLanguage   : true
---

## ç®€ä»‹

æœ€è¿‘æµ‹è¯•å¼€æºå¤§æ¨¡å‹çš„æ—¶å€™ï¼Œé‡åˆ°äº†ä¸€ä¸ªæŒºéšè”½çš„ silent errorï¼Œå€¼å¾—è®°å½•ä¸€ä¸‹ã€‚

å…·ä½“ç°è±¡æ˜¯è¿™æ ·ï¼š
1. å‡ ä¸ª Chat å¤§æ¨¡å‹çš„è¡¨ç°åƒæ˜¯åœ¨åšåŸºç¡€æ¨¡å‹çš„ç»­å†™ï¼Œä¸åƒæ˜¯å¯¹è¯ã€‚
2. ä½†ä»–ä»¬åœ¨ MaaS æˆ– HuggingFace Space ä¸Šçš„è¡¨ç°å´æ˜æ˜¾æ˜¯å¯¹è¯ã€‚

å…¶ä¸­ä¸€ä¸ªæ¨¡å‹æ˜¯é˜¿é‡Œå¼€æºçš„ Qwen/Qwen1.5-14B-Chatã€‚åœ¨é˜¿é‡Œäº‘çš„çµç§¯ MaaS ä¸Šå®ƒçš„è¡¨ç°å¾ˆç¬¦åˆé¢„æœŸï¼Œå°±æ˜¯å¯¹è¯ã€‚è€Œæˆ‘ä»¬è‡ªå·±è·‘èµ·æ¥æµ‹è¯•çš„æ—¶å€™å°±æ˜¯ç»­å†™ã€‚

## é¡¹ç›®

æˆ‘ä»¬çš„é¡¹ç›®ä½¿ç”¨äº† LangChain v0.1.16 å’Œ Transformers v4.40.1ã€‚ä»£ç å¤§è‡´æ˜¯è¿™æ ·ï¼š

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline

tokenizer = AutoTokenizer.from_pretrained(...)
model = AutoModelForCausalLM.from_pretrained(...)
pipe = pipeline("text-generation", model, tokenizer)

from langchain_core.prompts import ChatPromptTemplate
from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline

prompt = ChatPromptTemplate.from_messages([
    ('system', 'Youâ€™re a chatbot'),
    ('user', 'Hey')
])
llm = HuggingFacePipeline(pipeline=pipe)

chain = prompt | llm | ...
```

## è§£å†³

ä»”ç»†æ£€æŸ¥ä»£ç å’Œä¸‹è½½çš„æ¨¡å‹ï¼Œæˆ‘ä»¬å¹¶æ²¡æœ‰å‘ç°é—®é¢˜ã€‚æˆ‘çš„åŒäº‹å›½æ°å‚è€ƒå®˜æ–¹ demo å†™äº†ä¸€ä¸ªæµ‹è¯•è„šæœ¬æ¥æ‰§è¡Œæˆ‘ä»¬çš„ä»»åŠ¡ï¼Œè¡¨ç°ç¬¦åˆé¢„æœŸï¼Œæ˜¯å¯¹è¯ã€‚

äºæ˜¯å°±åœ¨æˆ‘ä»¬çš„é¡¹ç›®é‡Œè‡ªå®šä¹‰äº†ä¸€ä¸ª`CustomPromptTemplate`ï¼Œæ›¿æ¢æ‰ LangChain çš„`ChatPromptTemplate`ï¼Œå¤§è‡´æ˜¯ï¼š
```python
from langchain_core.prompts import StringPromptTemplate
from transformers import PreTrainedTokenizer, PreTrainedTokenizerFast

class CustomPromptTemplate(StringPromptTemplate):
    tokenizer: PreTrainedTokenizer | PreTrainedTokenizerFast

    def format(self, **kwargs):
        messages = [
            {"role": "system", "content": "Youâ€™re a chatbot"},
            {"role": "user", "content": "Hey"}
        ]

        return self.tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True
        )

tokenizer = AutoTokenizer.from_pretrained(...)
...
prompt = CustomPromptTemplate(tokenizer)
chain = prompt | llm | ...
```

å†æµ‹è¯•ï¼Œå‘ç°æˆ‘ä»¬çš„é¡¹ç›®é‡Œå¼€æºå¤§æ¨¡å‹çš„è¾“å‡ºä¹Ÿæ˜¯å¯¹è¯äº†ã€‚

åˆ°æ­¤ï¼Œé—®é¢˜å·²ç»è§£å†³äº†ã€‚æˆ‘å¯¹å…¶ä¸­çš„ç—‡ç»“äº§ç”Ÿäº†å…´è¶£ï¼Œä¹Ÿæƒ³æ’æŸ¥æ˜¯å¦ä¼šå¼•å…¥å…¶ä»–æ½œåœ¨é—®é¢˜ã€‚æ‰€ä»¥é¡ºç€è§£å†³æ–¹æ¡ˆç»§ç»­åˆ†æã€‚

## åˆ†æ

é¦–å…ˆæ¥çœ‹ LangChain å’Œ Transformers æ­é…ä½¿ç”¨æ—¶çš„å…³é”®è°ƒç”¨é“¾è·¯ï¼š

![Call Sequence](images/Call-Sequence.png)

å…³é”®ç‚¹æ˜¯å³ä¸‹è§’çš„`__call__`å’Œ`preprocess`ä¸¤ä¸ªæ–¹æ³•ï¼Œæ¥çœ‹çœ‹ Transformers çš„å…³é”®ä»£ç ï¼ˆå®Œæ•´ä»£ç è§ [text_generation.py](https://github.com/huggingface/Transformers/blob/c712d05aa8fc8ba3ebe465079bd377d2dc9c2e07/src/Transformers/pipelines/text_generation.py#L246)ï¼‰ï¼š
```python
class TextGenerationPipeline(Pipeline):
    def __call__(self, text_inputs, **kwargs):
        if isinstance(text_inputs, (list, tuple)) and isinstance(text_inputs[0], (list, tuple, dict)):
            # We have one or more prompts in list-of-dicts format, so this is chat mode
            if isinstance(text_inputs[0], dict):
                return super().__call__(Chat(text_inputs), **kwargs)
            else:
                chats = [Chat(chat) for chat in text_inputs]  # ğŸˆ ğŸˆ ğŸˆ
                return super().__call__(chats, **kwargs)
        else:
            return super().__call__(text_inputs, **kwargs)

    def preprocess(
        self,
        prompt_text,
		...
    ):
        if isinstance(prompt_text, Chat):
            inputs = self.tokenizer.apply_chat_template(
                prompt_text.messages,
				...
            )
        else:
            inputs = self.tokenizer(
                prefix + prompt_text,
                ...
            )
        	...
```
ä»`__call__`çš„ä»£ç ä¸­å¯ä»¥çœ‹å‡ºï¼Œå‚æ•°`text_inputs`å¿…é¡»ç¬¦åˆä¸€äº›ç±»å‹è¦æ±‚ï¼Œæ‰ä¼šè¢« Transformers å½“ä½œå¯¹è¯å¤„ç†ï¼Œåç»­æ‰§è¡Œåˆ°`preprocess`æ–¹æ³•æ—¶æ‰ä¼šè°ƒç”¨`tokenizer.apply_chat_template`ã€‚

ä»€ä¹ˆç±»å‹æ‰ç¬¦åˆè¦æ±‚å‘¢ï¼ŸTransformers æœ€å¸¸è§„çš„ç”¨æ³•å°±ç¬¦åˆï¼Œæ¯”å¦‚ï¼š
```python
messages = [
    {"role": "system", "content": "Youâ€™re a chatbot"},
    {"role": "user", "content": "Hey"}
]
```
å®ƒçš„ç±»å‹æ˜¯`list[dict]`ã€‚

è€Œ LangChain æä¾›çš„ text_inputs ä¸ç¬¦åˆè¿™äº›è¦æ±‚ï¼Œå°±èµ°åˆ°äº† else åˆ†æ”¯ï¼Œåç»­åœ¨`preprocess`æ–¹æ³•é‡Œæ²¡æœ‰è°ƒç”¨`tokenizer.apply_chat_template`ï¼Œè¢«å½“ä½œéå¯¹è¯å¤„ç†äº†ã€‚

å…·ä½“æ¥è¯´æ˜¯è¿™æ ·ï¼Œä»¥ LangChain å¸¸è§çš„ prompt template ç”¨æ³•ä¸ºä¾‹ï¼š
```
prompt = ChatPromptTemplate.from_messages([
    ('system', 'Youâ€™re a chatbot'),
    ('user', 'Hey')
])
```

LangChain æä¾›ç»™ Transformers çš„ text_inputs æ˜¯è¿™æ ·çš„ï¼š
```python
[
	"System: \nYouâ€™re a chatbot\n\nHuman:Hey"
]
```
å®ƒçš„ç±»å‹æ˜¯`list[str]`ã€‚

åˆ°è¿™é‡Œï¼Œåˆ†æç»“æŸã€‚æˆ‘ä»¬æœ‰ä¸¤ç§è§£å†³æ–¹æ¡ˆï¼š
1. åœ¨è°ƒç”¨ Transformers ä¹‹å‰å¯¹ prompt è°ƒç”¨`tokenizer.apply_chat_template`ã€‚è¿™ä¹Ÿæ˜¯å‰è¿°æˆ‘åŒäº‹å›½æ°é‡‡ç”¨çš„æ–¹æ³•ã€‚
2. æä¾›ç¬¦åˆ Transformers éœ€è¦çš„ prompt æ ¼å¼ï¼Œæ¯”å¦‚ä¸Šé¢æåˆ°çš„`list[dict]`ï¼Œç”± Transformers åœ¨å…¶å†…éƒ¨è°ƒç”¨`tokenizer.apply_chat_template`ã€‚

å¦‚æœä½ å¯¹ä¸ºä»€ä¹ˆ`tokenizer.apply_chat_template`è¿™ä¹ˆå…³é”®æ„Ÿåˆ°å¥½å¥‡ï¼Œå¯ä»¥é˜…è¯»è¿™ä¸¤ç¯‡æ–‡ç« ï¼š
1. https://huggingface.co/docs/Transformers/chat_templating
2. https://huggingface.co/blog/chat-templates
